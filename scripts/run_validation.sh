#!/bin/bash
# æ¤œè¨¼å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# Validation Execution Script

set -e

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã«ç§»å‹•
cd "$(dirname "$0")/.."

# ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
source venv/bin/activate

# å¼•æ•°ãƒã‚§ãƒƒã‚¯
if [ $# -eq 0 ]; then
    echo "Usage: $0 <batch_name> [llm_provider]"
    echo "Example: $0 'Sleep Function Test' ollama"
    exit 1
fi

BATCH_NAME="$1"
LLM_PROVIDER="${2:-ollama}"

echo "ğŸš€ Starting validation execution..."
echo "Batch Name: $BATCH_NAME"
echo "LLM Provider: $LLM_PROVIDER"
echo "Timestamp: $(date)"

# Pythonæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
python -c "
import sys
sys.path.append('.')

from app.services.validation_engine import get_validation_engine
from app.services.llm_service import get_llm_service
from app.models.validation import TestItem, TestCondition, TestCategory, EquipmentType
import uuid
from datetime import datetime

def create_sample_test_items():
    '''ã‚µãƒ³ãƒ—ãƒ«æ¤œè¨¼é …ç›®ã‚’ä½œæˆ'''
    items = []
    
    # åŸºåœ°å±€ã‚¹ãƒªãƒ¼ãƒ—æ©Ÿèƒ½ã®åŸºæœ¬æ¤œè¨¼
    item1 = TestItem(
        id=str(uuid.uuid4()),
        test_block='ESGé¸å®š',
        category=TestCategory.CM_DATA_ACQUISITION,
        condition=TestCondition(
            condition_text='CMãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸï¼ˆå…¨è¨­å‚™ï¼‰',
            expected_count=4,
            equipment_types=[
                EquipmentType.ERICSSON_MMU,
                EquipmentType.ERICSSON_RRU,
                EquipmentType.SAMSUNG_AUV1,
                EquipmentType.SAMSUNG_AUV2
            ]
        ),
        scenarios=['æ­£å¸¸ã‚¹ãƒªãƒ¼ãƒ—', 'ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿']
    )
    items.append(item1)
    
    return items

def main():
    print('Initializing validation engine...')
    engine = get_validation_engine('$LLM_PROVIDER')
    
    print('Creating test items...')
    test_items = create_sample_test_items()
    
    print('Creating validation batch...')
    batch = engine.create_batch_from_test_items(test_items, '$BATCH_NAME')
    
    print('Executing validation batch...')
    def progress_callback(progress, result):
        print(f'Progress: {progress:.1%} - Latest: {result.equipment_type.value} -> {result.result.value}')
    
    completed_batch = engine.execute_batch(batch, progress_callback)
    
    print('\\nğŸ“Š Validation Results:')
    summary = engine.get_batch_summary(completed_batch)
    print(f'Total Tests: {summary[\"total_tests\"]}')
    print(f'Success Rate: {summary[\"success_rate\"]:.1%}')
    print(f'Average Execution Time: {summary[\"average_execution_time\"]:.2f}s')
    print(f'Status: {summary[\"status\"]}')
    
    print('\\nğŸ‰ Validation completed successfully!')

if __name__ == '__main__':
    main()
"

echo "âœ… Validation execution completed!"
echo "Check the results in the Streamlit dashboard."



