#!/usr/bin/env python3
"""
Streamlitç”¨LLMãƒ†ã‚¹ãƒˆ
"""

import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.services.llm_service import LLMService

def main():
    print('ğŸ” Streamlitç”¨LLMãƒ†ã‚¹ãƒˆ')
    
    # Ollama
    print('\nğŸ“± Ollama:')
    try:
        llm = LLMService('ollama')
        items = llm.generate_test_items('åŸºåœ°å±€ã‚¹ãƒªãƒ¼ãƒ—æ©Ÿèƒ½', ['ERICSSON_MMU'])
        print(f'âœ… æˆåŠŸ: {len(items)}ä»¶ç”Ÿæˆ')
        if items:
            print(f'  ä¾‹: {items[0].get("condition_text", "")}')
    except Exception as e:
        print(f'âŒ ã‚¨ãƒ©ãƒ¼: {e}')
    
    # AWS Bedrock
    print('\nâ˜ï¸ AWS Bedrock:')
    try:
        llm = LLMService('bedrock')
        items = llm.generate_test_items('åŸºåœ°å±€ã‚¹ãƒªãƒ¼ãƒ—æ©Ÿèƒ½', ['ERICSSON_MMU'])
        print(f'âœ… æˆåŠŸ: {len(items)}ä»¶ç”Ÿæˆ')
        if items:
            print(f'  ä¾‹: {items[0].get("condition_text", "")}')
    except Exception as e:
        print(f'âŒ ã‚¨ãƒ©ãƒ¼: {e}')

if __name__ == "__main__":
    main()

