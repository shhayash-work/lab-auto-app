# ğŸ”§ æŠ€è¡“è©³ç´°èª¬æ˜æ›¸

**Technical Details Documentation**

ãƒ©ãƒœæ¤œè¨¼è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®æŠ€è¡“çš„ãªè©³ç´°ã«ã¤ã„ã¦ã€åˆç´šè€…ã«ã‚‚åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¾ã™ã€‚

## ğŸ“‹ ç›®æ¬¡

1. [ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åƒ](#ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åƒ)
2. [ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°](#ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°)
3. [ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼](#ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼)
4. [å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°](#å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°)
5. [å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯](#å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯)
6. [ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ](#ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ)
7. [APIä»•æ§˜](#apiä»•æ§˜)
8. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“åƒ

### æ¦‚è¦
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€é€šä¿¡äº‹æ¥­è€…ã®ãƒ©ãƒœæ¤œè¨¼ä½œæ¥­ã‚’è‡ªå‹•åŒ–ã™ã‚‹ãŸã‚ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚ä»¥ä¸‹ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã§æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ï¼š

- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: Streamlit (Python Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯)
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰**: Python 3.12
- **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: SQLite (è»½é‡ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«DB)
- **AI/LLM**: Ollama + llama3.3:latest
- **ãƒ¢ãƒƒã‚¯è¨­å‚™**: ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼

### ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³

```mermaid
graph TB
    subgraph "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å±¤"
        A[Streamlit Dashboard]
        B[Web Browser]
    end
    
    subgraph "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤"
        C[Main Application]
        D[LLM Service]
        E[Validation Engine]
        F[Excel Parser]
        G[Star Chart Generator]
    end
    
    subgraph "ãƒ‡ãƒ¼ã‚¿å±¤"
        H[SQLite Database]
        I[Vector Store]
        J[File Storage]
    end
    
    subgraph "å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ "
        K[Ollama LLM]
        L[Mock Equipment]
    end
    
    B --> A
    A --> C
    C --> D
    C --> E
    C --> F
    C --> G
    D --> K
    E --> L
    C --> H
    D --> I
    C --> J
```

## ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

### 1. æ¤œè¨¼é …ç›®ä½œæˆãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant User as ãƒ¦ãƒ¼ã‚¶ãƒ¼
    participant UI as Streamlit UI
    participant LLM as LLM Service
    participant DB as Database
    
    User->>UI: æ–°æ©Ÿèƒ½åå…¥åŠ›
    UI->>LLM: æ¤œè¨¼é …ç›®ç”Ÿæˆè¦æ±‚
    LLM->>LLM: RAGæ¤œç´¢ + ç”Ÿæˆ
    LLM->>UI: ç”Ÿæˆã•ã‚ŒãŸæ¤œè¨¼é …ç›®
    UI->>DB: æ¤œè¨¼é …ç›®ä¿å­˜
    DB->>UI: ä¿å­˜å®Œäº†
    UI->>User: çµæœè¡¨ç¤º
```

### 2. æ¤œè¨¼å®Ÿè¡Œãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant UI as Streamlit UI
    participant Engine as Validation Engine
    participant Mock as Mock Equipment
    participant LLM as LLM Service
    participant DB as Database
    
    UI->>Engine: æ¤œè¨¼ãƒãƒƒãƒå®Ÿè¡Œ
    Engine->>Mock: è¨­å‚™ã‚³ãƒãƒ³ãƒ‰é€ä¿¡
    Mock->>Engine: è¨­å‚™å¿œç­”ãƒ‡ãƒ¼ã‚¿
    Engine->>LLM: çµæœåˆ†æè¦æ±‚
    LLM->>Engine: åˆ¤å®šçµæœ
    Engine->>DB: çµæœä¿å­˜
    Engine->>UI: é€²æ—é€šçŸ¥
    UI->>UI: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºæ›´æ–°
```

## ğŸ§© å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°

### 1. Streamlit UI (`app/main.py`)

**å½¹å‰²**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®æä¾›

**ä¸»è¦æ©Ÿèƒ½**:
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¡¨ç¤º
- æ¤œè¨¼é …ç›®ç®¡ç†
- æ¤œè¨¼å®Ÿè¡Œåˆ¶å¾¡
- çµæœè¡¨ç¤ºãƒ»åˆ†æ

**å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ**:
```python
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
if 'initialized' not in st.session_state:
    st.session_state.initialized = True
    st.session_state.test_items = []

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°
def progress_callback(progress: float, result: ValidationResult):
    progress_bar.progress(progress)
    status_text.text(f"å®Ÿè¡Œä¸­... {progress:.1%} å®Œäº†")
```

### 2. LLM Service (`app/services/llm_service.py`)

**å½¹å‰²**: å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã®é€£æº

**å¯¾å¿œãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼**:
- Ollama (ãƒ­ãƒ¼ã‚«ãƒ«)
- OpenAI GPT-4o
- Anthropic Claude
- AWS Bedrock

**ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰**:

#### `analyze_validation_result()`
```python
def analyze_validation_result(self, test_item: Dict, equipment_response: Dict) -> Dict:
    """
    æ¤œè¨¼çµæœã‚’LLMã§åˆ†æ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
    2. æ¤œè¨¼é …ç›®ã¨è¨­å‚™å¿œç­”ã‚’çµ„ã¿åˆã‚ã›
    3. LLMã«åˆ†æè¦æ±‚
    4. JSONå½¢å¼ã®åˆ¤å®šçµæœã‚’å–å¾—
    5. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆã‚¨ãƒ©ãƒ¼æ™‚ï¼‰
    """
```

#### `generate_test_items()`
```python
def generate_test_items(self, feature_name: str, equipment_types: List[str]) -> List[Dict]:
    """
    æ–°æ©Ÿèƒ½ã®æ¤œè¨¼é …ç›®ã‚’AIç”Ÿæˆ
    
    å‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. æ©Ÿèƒ½åã¨è¨­å‚™ã‚¿ã‚¤ãƒ—ã‚’å…¥åŠ›
    2. éå»ã®æ¤œè¨¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‚ç…§ï¼ˆRAGï¼‰
    3. æ–°è¦æ¤œè¨¼é …ç›®ã‚’ç”Ÿæˆ
    4. æ˜Ÿå–è¡¨å½¢å¼ã§å‡ºåŠ›
    """
```

### 3. Validation Engine (`app/services/validation_engine.py`)

**å½¹å‰²**: æ¤œè¨¼ã®å®Ÿè¡Œåˆ¶å¾¡ã¨ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**ä¸»è¦ã‚¯ãƒ©ã‚¹**: `ValidationEngine`

**å®Ÿè¡Œãƒ•ãƒ­ãƒ¼**:

#### å˜ä¸€æ¤œè¨¼å®Ÿè¡Œ
```python
def execute_test_item(self, test_item: TestItem, scenario: str, equipment_type: EquipmentType):
    """
    1. é–‹å§‹æ™‚åˆ»è¨˜éŒ²
    2. ã‚³ãƒãƒ³ãƒ‰æ±ºå®šï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ï¼‰
    3. ãƒ¢ãƒƒã‚¯è¨­å‚™ã«ã‚³ãƒãƒ³ãƒ‰é€ä¿¡
    4. è¨­å‚™å¿œç­”å—ä¿¡
    5. LLMã§çµæœåˆ†æ
    6. ValidationResultã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
    7. å®Ÿè¡Œæ™‚é–“è¨ˆç®—
    """
```

#### ãƒãƒƒãƒå®Ÿè¡Œ
```python
def execute_batch(self, batch: ValidationBatch, progress_callback):
    """
    1. ãƒãƒƒãƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ï¼ˆRUNNINGï¼‰
    2. å®Ÿè¡Œã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆä½œæˆ
    3. ThreadPoolExecutorã§ä¸¦åˆ—å®Ÿè¡Œ
    4. é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å‘¼ã³å‡ºã—
    5. çµæœåé›†ãƒ»é›†è¨ˆ
    6. ãƒãƒƒãƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ï¼ˆCOMPLETEDï¼‰
    """
```

### 4. Mock Equipment System (`mock_equipment/equipment_simulator.py`)

**å½¹å‰²**: å®Ÿéš›ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å‚™ã‚’æ¨¡æ“¬

**è¨­å‚™ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼éšå±¤**:
```
BaseEquipmentSimulator (åŸºåº•ã‚¯ãƒ©ã‚¹)
â”œâ”€â”€ EricssonMMUSimulator
â”œâ”€â”€ EricssonRRUSimulator  
â”œâ”€â”€ SamsungAUv1Simulator
â””â”€â”€ SamsungAUv2Simulator
```

**å¿œç­”ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯**:

#### Ericsson MMUä¾‹
```python
def get_cm_data(self) -> Dict[str, Any]:
    """
    1. å®Ÿè¡Œæ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ1-3ç§’ï¼‰
    2. æˆåŠŸ/å¤±æ•—ã‚’ãƒ©ãƒ³ãƒ€ãƒ æ±ºå®šï¼ˆ90%æˆåŠŸç‡ï¼‰
    3. SNMP MIBã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
    4. è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    5. JSONå½¢å¼ã§å¿œç­”è¿”å´
    """
    
    # SNMP MIBå½¢å¼ï¼ˆå®Ÿéš›ã®åŸºåœ°å±€ã«æº–æ‹ ï¼‰
    snmp_data = {
        "1.3.6.1.4.1.193.183.4.1.3.4.1.1": "Cell_12345",  # cellId
        "1.3.6.1.4.1.193.183.4.1.4.1.1": -75.2,           # RSRP
    }
    
    # äººé–“ãŒèª­ã¿ã‚„ã™ã„å½¢å¼
    parsed_data = {
        "cell_id": "Cell_12345",
        "signal_strength_dbm": -75.2,
        "throughput_mbps": 150.5
    }
```

**å‚è€ƒã«ã—ãŸãƒ‡ãƒ¼ã‚¿å½¢å¼**:
- **SNMP MIB**: [RFC 1213](https://tools.ietf.org/html/rfc1213)
- **EricssonåŸºåœ°å±€**: 1.3.6.1.4.1.193.183.*
- **SamsungåŸºåœ°å±€**: 1.3.6.1.4.1.20858.*

### 5. Database Models (`app/models/database.py`)

**å½¹å‰²**: ãƒ‡ãƒ¼ã‚¿ã®æ°¸ç¶šåŒ–ã¨ORM

**ä½¿ç”¨æŠ€è¡“**: SQLAlchemy + SQLite

**ä¸»è¦ãƒ†ãƒ¼ãƒ–ãƒ«**:

#### TestItemDB
```python
class TestItemDB(Base):
    __tablename__ = "test_items"
    
    id = Column(String, primary_key=True)
    test_block = Column(String, nullable=False)
    category = Column(String, nullable=False)
    condition_text = Column(Text, nullable=False)
    expected_count = Column(Integer, default=0)
    threshold_values = Column(Text)  # JSONæ–‡å­—åˆ—
    equipment_types = Column(Text)   # JSONæ–‡å­—åˆ—
    scenarios = Column(Text)         # JSONæ–‡å­—åˆ—
```

**JSONåˆ—ã®å‡¦ç†**:
```python
def set_threshold_values(self, values: Dict[str, float]):
    """è¾æ›¸ã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜"""
    self.threshold_values = json.dumps(values)

def get_threshold_values(self) -> Dict[str, float]:
    """JSONæ–‡å­—åˆ—ã‚’è¾æ›¸ã¨ã—ã¦å–å¾—"""
    if self.threshold_values:
        return json.loads(self.threshold_values)
    return {}
```

### 6. Excel Parser (`app/utils/excel_parser.py`)

**å½¹å‰²**: Excelãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®æ¤œè¨¼é …ç›®æŠ½å‡º

**å‡¦ç†ãƒ•ãƒ­ãƒ¼**:
```python
def parse_excel_test_items(uploaded_file) -> List[TestItem]:
    """
    1. pandasã§Excelèª­ã¿è¾¼ã¿
    2. åˆ—åã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’åˆ†æ
    3. å„è¡Œã‚’æ¤œè¨¼é …ç›®ã«å¤‰æ›
    4. è¨­å‚™ã‚¿ã‚¤ãƒ—ã¨ã‚·ãƒŠãƒªã‚ªã‚’æŠ½å‡º
    5. TestItemã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆç”Ÿæˆ
    6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    """
```

**åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°ä¾‹**:
```python
# Excelã®åˆ—åã‹ã‚‰è¨­å‚™ã‚¿ã‚¤ãƒ—ã‚’ç‰¹å®š
if 'Ericsson-MMU' in col_str:
    equipment_type = EquipmentType.ERICSSON_MMU
elif 'Samsung-AUv1' in col_str:
    equipment_type = EquipmentType.SAMSUNG_AUV1
```

### 7. Star Chart Generator (`app/utils/star_chart.py`)

**å½¹å‰²**: æ¤œè¨¼çµæœã®æ˜Ÿå–è¡¨ç”Ÿæˆ

**å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯**:
```python
def convert_result_to_symbol(result: TestResult) -> str:
    """ãƒ†ã‚¹ãƒˆçµæœã‚’è¨˜å·ã«å¤‰æ›"""
    symbol_mapping = {
        TestResult.PASS: "â—",        # åˆæ ¼
        TestResult.FAIL: "Ã—",        # ä¸åˆæ ¼  
        TestResult.WARNING: "â–³",     # è­¦å‘Š
        TestResult.NOT_EXECUTED: "-" # æœªå®Ÿè¡Œ
    }
    return symbol_mapping.get(result, "-")
```

**DataFrameç”Ÿæˆ**:
```python
def create_star_chart_dataframe(results: List[ValidationResult]) -> pd.DataFrame:
    """
    1. ã‚·ãƒŠãƒªã‚ªã¨è¨­å‚™ã‚¿ã‚¤ãƒ—ã‚’æŠ½å‡º
    2. çµæœãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ
    3. è¨˜å·å¤‰æ›é©ç”¨
    4. pandas DataFrameã¨ã—ã¦è¿”å´
    """
```

## ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­è¨ˆ

### ERå›³

```mermaid
erDiagram
    TEST_ITEMS {
        string id PK
        string test_block
        string category
        text condition_text
        integer expected_count
        text threshold_values
        text equipment_types
        text scenarios
        datetime created_at
        datetime updated_at
    }
    
    VALIDATION_BATCHES {
        string id PK
        string name
        string status
        datetime started_at
        datetime completed_at
        datetime created_at
    }
    
    VALIDATION_RESULTS {
        string id PK
        string test_item_id FK
        string batch_id FK
        string equipment_type
        string scenario
        string result
        text response_data
        float execution_time
        text error_message
        float confidence
        datetime created_at
    }
    
    LAB_LOCATIONS {
        string id PK
        string name
        string address
        text equipment_types
        integer capacity
        datetime created_at
    }
    
    KNOWLEDGE_ENTRIES {
        string id PK
        string test_item_id FK
        text failure_pattern
        text analysis
        text improvement_suggestion
        string created_by
        datetime created_at
    }
    
    TEST_ITEMS ||--o{ VALIDATION_RESULTS : "has"
    VALIDATION_BATCHES ||--o{ VALIDATION_RESULTS : "contains"
    TEST_ITEMS ||--o{ KNOWLEDGE_ENTRIES : "generates"
```

### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­è¨ˆ

```sql
-- æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_validation_results_batch_id ON validation_results(batch_id);
CREATE INDEX idx_validation_results_test_item_id ON validation_results(test_item_id);
CREATE INDEX idx_validation_results_created_at ON validation_results(created_at);
CREATE INDEX idx_test_items_category ON test_items(category);
```

## ğŸ”„ å®Ÿè£…ãƒ­ã‚¸ãƒƒã‚¯è©³ç´°

### 1. ä¸¦åˆ—å‡¦ç†å®Ÿè£…

**ThreadPoolExecutorä½¿ç”¨**:
```python
with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
    # ã‚¿ã‚¹ã‚¯ã‚’æŠ•å…¥
    future_to_task = {
        executor.submit(self.execute_test_item, test_item, scenario, equipment_type): 
        (test_item, scenario, equipment_type)
        for test_item, scenario, equipment_type in tasks
    }
    
    # çµæœã‚’åé›†
    for future in as_completed(future_to_task):
        result = future.result()
        batch.results.append(result)
```

**éåŒæœŸå‡¦ç†å¯¾å¿œ**:
```python
async def execute_batch_async(self, batch: ValidationBatch):
    """
    asyncio.Semaphoreã§åŒæ™‚å®Ÿè¡Œæ•°åˆ¶å¾¡
    asyncio.as_completedã§é †æ¬¡çµæœåé›†
    """
    semaphore = asyncio.Semaphore(self.max_workers)
    
    async def execute_with_semaphore(test_item, scenario, equipment_type):
        async with semaphore:
            loop = asyncio.get_event_loop()
            return await loop.run_in_executor(
                None, self.execute_test_item, test_item, scenario, equipment_type
            )
```

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥

**éšå±¤çš„ã‚¨ãƒ©ãƒ¼å‡¦ç†**:
```python
try:
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†
    result = self.execute_main_logic()
except SpecificException as e:
    # ç‰¹å®šã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
    logger.warning(f"Specific error: {e}")
    result = self.handle_specific_error(e)
except Exception as e:
    # æ±ç”¨ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†
    logger.error(f"Unexpected error: {e}")
    result = self.create_error_result(e)
finally:
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
    self.cleanup_resources()
```

**ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½**:
```python
def analyze_validation_result(self, test_item, equipment_response):
    """
    1. LLMã§åˆ†æè©¦è¡Œ
    2. JSONãƒ‘ãƒ¼ã‚¹è©¦è¡Œ
    3. å¤±æ•—æ™‚ã¯ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    4. æœ€çµ‚çš„ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”å´
    """
    try:
        llm_result = self.llm_service.analyze(...)
        return json.loads(llm_result)
    except (json.JSONDecodeError, LLMException):
        logger.warning("LLM analysis failed, using fallback")
        return self._fallback_analysis(equipment_response)
```

### 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

**Streamlitã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹**:
```python
# é‡ã„å‡¦ç†ã®çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
@st.cache_data
def load_test_items():
    """æ¤œè¨¼é …ç›®ã®èª­ã¿è¾¼ã¿çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    return database_manager.get_all_test_items()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ä¿æŒ
if 'validation_results' not in st.session_state:
    st.session_state.validation_results = []
```

**LLMæ¥ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥**:
```python
def _test_ollama_connection(self):
    """æ¥ç¶šãƒ†ã‚¹ãƒˆçµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
    cache_key = f"ollama_tested_{OLLAMA_BASE_URL}_{OLLAMA_MODEL}"
    
    if not self.force_test and cache_key in st.session_state:
        cached_result = st.session_state[cache_key]
        logger.info("âš¡ Using cached Ollama connection")
        return cached_result
```

### 4. ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**ãƒ¢ãƒ‡ãƒ«é–“å¤‰æ›**:
```python
# Domain Model â†’ Database Model
def to_db_model(test_item: TestItem) -> TestItemDB:
    db_item = TestItemDB(
        id=test_item.id,
        test_block=test_item.test_block,
        category=test_item.category.value
    )
    db_item.set_equipment_types([eq.value for eq in test_item.condition.equipment_types])
    return db_item

# Database Model â†’ Domain Model  
def from_db_model(db_item: TestItemDB) -> TestItem:
    equipment_types = [EquipmentType(eq) for eq in db_item.get_equipment_types()]
    condition = TestCondition(
        condition_text=db_item.condition_text,
        equipment_types=equipment_types
    )
    return TestItem(
        id=db_item.id,
        test_block=db_item.test_block,
        category=TestCategory(db_item.category),
        condition=condition
    )
```

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®Ÿè£…

### 1. å…¥åŠ›æ¤œè¨¼

**SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–**:
```python
# SQLAlchemy ORMã‚’ä½¿ç”¨ï¼ˆè‡ªå‹•ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ï¼‰
session.query(TestItemDB).filter(TestItemDB.id == user_input).first()

# ç›´æ¥SQLå®Ÿè¡Œæ™‚ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã‚¯ã‚¨ãƒª
session.execute(
    text("SELECT * FROM test_items WHERE id = :id"),
    {"id": user_input}
)
```

**ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¤œè¨¼**:
```python
def validate_uploaded_file(uploaded_file):
    """
    1. ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
    2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™
    3. MIMEã‚¿ã‚¤ãƒ—æ¤œè¨¼
    4. ã‚¦ã‚¤ãƒ«ã‚¹ã‚¹ã‚­ãƒ£ãƒ³ï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
    """
    allowed_extensions = ['.xlsx', '.xls']
    max_size = 10 * 1024 * 1024  # 10MB
    
    if not any(uploaded_file.name.endswith(ext) for ext in allowed_extensions):
        raise ValueError("Invalid file type")
    
    if uploaded_file.size > max_size:
        raise ValueError("File too large")
```

### 2. èªè¨¼ãƒ»èªå¯

**ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹è¨­å®š**:
```python
# APIã‚­ãƒ¼ã®å®‰å…¨ãªç®¡ç†
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("OpenAI API key not configured")

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®åˆ¶å¾¡
DEBUG = os.getenv("DEBUG", "false").lower() == "true"
if DEBUG:
    logging.basicConfig(level=logging.DEBUG)
```

### 3. ãƒ­ã‚°ç®¡ç†

**ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–æƒ…å ±ã®é™¤å¤–**:
```python
def safe_log_response(response_data: Dict) -> Dict:
    """ãƒ­ã‚°å‡ºåŠ›ç”¨ã«ã‚»ãƒ³ã‚·ãƒ†ã‚£ãƒ–æƒ…å ±ã‚’é™¤å¤–"""
    safe_data = response_data.copy()
    
    # APIã‚­ãƒ¼ã‚„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é™¤å¤–
    sensitive_keys = ['api_key', 'token', 'password']
    for key in sensitive_keys:
        if key in safe_data:
            safe_data[key] = "***REDACTED***"
    
    return safe_data

logger.info(f"Equipment response: {safe_log_response(response)}")
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–

**æ¥ç¶šãƒ—ãƒ¼ãƒ«**:
```python
# SQLAlchemyæ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š
engine = create_engine(
    DATABASE_URL,
    pool_size=10,           # æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚º
    max_overflow=20,        # æœ€å¤§ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼
    pool_timeout=30,        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    pool_recycle=3600       # æ¥ç¶šãƒªã‚µã‚¤ã‚¯ãƒ«
)
```

**ãƒãƒƒãƒå‡¦ç†**:
```python
def bulk_insert_results(results: List[ValidationResult]):
    """ãƒãƒƒãƒã§ã®çµæœæŒ¿å…¥"""
    session = db_manager.get_session()
    try:
        db_results = [result.to_db_model() for result in results]
        session.bulk_save_objects(db_results)
        session.commit()
    finally:
        session.close()
```

### 2. ãƒ¡ãƒ¢ãƒªç®¡ç†

**ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ä½¿ç”¨**:
```python
def process_large_dataset():
    """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’é€æ¬¡å‡¦ç†"""
    for batch in get_data_batches():
        yield process_batch(batch)
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del batch
```

**ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ¼ãƒ«**:
```python
class ValidationEnginePool:
    """æ¤œè¨¼ã‚¨ãƒ³ã‚¸ãƒ³ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒ—ãƒ¼ãƒ«"""
    def __init__(self, pool_size=5):
        self.pool = Queue(maxsize=pool_size)
        for _ in range(pool_size):
            self.pool.put(ValidationEngine())
    
    def get_engine(self):
        return self.pool.get()
    
    def return_engine(self, engine):
        self.pool.put(engine)
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 1. å˜ä½“ãƒ†ã‚¹ãƒˆ

**pytestä½¿ç”¨ä¾‹**:
```python
def test_validation_engine():
    """æ¤œè¨¼ã‚¨ãƒ³ã‚¸ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
    engine = ValidationEngine()
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    test_item = create_test_item()
    
    # å®Ÿè¡Œ
    result = engine.execute_test_item(
        test_item, "æ­£å¸¸ã‚¹ãƒªãƒ¼ãƒ—", EquipmentType.ERICSSON_MMU
    )
    
    # æ¤œè¨¼
    assert result.test_item_id == test_item.id
    assert result.result in [TestResult.PASS, TestResult.FAIL, TestResult.WARNING]
    assert result.execution_time > 0
```

### 2. çµ±åˆãƒ†ã‚¹ãƒˆ

**ãƒ¢ãƒƒã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½¿ç”¨**:
```python
@patch('app.services.llm_service.ollama.Client')
def test_llm_service_integration(mock_ollama):
    """LLMã‚µãƒ¼ãƒ“ã‚¹ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    # ãƒ¢ãƒƒã‚¯è¨­å®š
    mock_ollama.return_value.chat.return_value = {
        'message': {'content': '{"result": "PASS", "confidence": 0.9}'}
    }
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    llm_service = LLMService()
    result = llm_service.analyze_validation_result(test_item, response)
    
    # æ¤œè¨¼
    assert result['result'] == 'PASS'
    assert result['confidence'] == 0.9
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

**å®Ÿè¡Œæ™‚é–“æ¸¬å®š**:
```python
def test_validation_performance():
    """æ¤œè¨¼å®Ÿè¡Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
    engine = ValidationEngine()
    test_items = create_large_test_batch(100)
    
    start_time = time.time()
    batch = engine.execute_batch(test_items)
    execution_time = time.time() - start_time
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ãƒã‚§ãƒƒã‚¯
    assert execution_time < 300  # 5åˆ†ä»¥å†…
    assert batch.success_rate > 0.8  # 80%ä»¥ä¸Šã®æˆåŠŸç‡
```

## ğŸ”§ ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š

```python
# é–‹ç™ºæ™‚ã®è©³ç´°ãƒ­ã‚°
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)

# æœ¬ç•ªæ™‚ã®æœ€å°ãƒ­ã‚°
logging.basicConfig(level=logging.WARNING)
```

### 2. ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

```python
def debug_validation_result(result: ValidationResult):
    """æ¤œè¨¼çµæœã®ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›"""
    print(f"=== Validation Result Debug ===")
    print(f"Test Item ID: {result.test_item_id}")
    print(f"Equipment: {result.equipment_type.value}")
    print(f"Scenario: {result.scenario}")
    print(f"Result: {result.result.value}")
    print(f"Execution Time: {result.execution_time:.2f}s")
    print(f"Confidence: {result.confidence:.2f}")
    if result.error_message:
        print(f"Error: {result.error_message}")
    print(f"Response Data: {json.dumps(result.response_data, indent=2)}")
    print("=" * 30)
```

### 3. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½

```python
def system_health_check():
    """ã‚·ã‚¹ãƒ†ãƒ ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
    health_status = {
        "database": check_database_connection(),
        "ollama": check_ollama_connection(),
        "mock_equipment": check_mock_equipment(),
        "disk_space": check_disk_space(),
        "memory_usage": check_memory_usage()
    }
    
    return health_status

def check_database_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯"""
    try:
        session = db_manager.get_session()
        session.execute(text("SELECT 1"))
        session.close()
        return {"status": "healthy", "message": "Database connection OK"}
    except Exception as e:
        return {"status": "unhealthy", "message": str(e)}
```

## ğŸ“ˆ ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### 1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
class PerformanceMonitor:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.metrics = {
            "validation_count": 0,
            "total_execution_time": 0.0,
            "success_count": 0,
            "failure_count": 0
        }
    
    def record_validation(self, result: ValidationResult):
        """æ¤œè¨¼çµæœã‚’è¨˜éŒ²"""
        self.metrics["validation_count"] += 1
        self.metrics["total_execution_time"] += result.execution_time
        
        if result.result == TestResult.PASS:
            self.metrics["success_count"] += 1
        else:
            self.metrics["failure_count"] += 1
    
    def get_average_execution_time(self):
        """å¹³å‡å®Ÿè¡Œæ™‚é–“ã‚’å–å¾—"""
        if self.metrics["validation_count"] > 0:
            return self.metrics["total_execution_time"] / self.metrics["validation_count"]
        return 0.0
    
    def get_success_rate(self):
        """æˆåŠŸç‡ã‚’å–å¾—"""
        total = self.metrics["validation_count"]
        if total > 0:
            return self.metrics["success_count"] / total
        return 0.0
```

### 2. ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½

```python
def check_system_alerts():
    """ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆã®ãƒã‚§ãƒƒã‚¯"""
    alerts = []
    
    # æˆåŠŸç‡ãŒä½ä¸‹ã—ãŸå ´åˆ
    if performance_monitor.get_success_rate() < 0.7:
        alerts.append({
            "level": "warning",
            "message": "Validation success rate below 70%"
        })
    
    # å®Ÿè¡Œæ™‚é–“ãŒé•·ã™ãã‚‹å ´åˆ
    if performance_monitor.get_average_execution_time() > 10.0:
        alerts.append({
            "level": "warning", 
            "message": "Average execution time exceeds 10 seconds"
        })
    
    # ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³
    if get_disk_usage() > 0.9:
        alerts.append({
            "level": "critical",
            "message": "Disk usage above 90%"
        })
    
    return alerts
```

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### 1. æœ¬ç•ªç’°å¢ƒè¨­å®š

```bash
# æœ¬ç•ªç”¨ç’°å¢ƒå¤‰æ•°
export ENVIRONMENT=production
export DEBUG=false
export LOG_LEVEL=WARNING
export DATABASE_URL=postgresql://user:pass@host:5432/labvalidation

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
export SECRET_KEY=your-secret-key
export ALLOWED_HOSTS=your-domain.com
```

### 2. DockeråŒ–

```dockerfile
FROM python:3.12-slim

WORKDIR /app

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ”ãƒ¼
COPY . .

# érootãƒ¦ãƒ¼ã‚¶ãƒ¼ã§å®Ÿè¡Œ
RUN useradd -m appuser
USER appuser

# ãƒãƒ¼ãƒˆå…¬é–‹
EXPOSE 8501

# èµ·å‹•ã‚³ãƒãƒ³ãƒ‰
CMD ["streamlit", "run", "app/main.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

### 3. é‹ç”¨ç›£è¦–

```python
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯API"""
    health_status = system_health_check()
    
    if all(status["status"] == "healthy" for status in health_status.values()):
        return {"status": "healthy", "details": health_status}
    else:
        raise HTTPException(status_code=503, detail=health_status)

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.get("/metrics")
async def get_metrics():
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—API"""
    return {
        "validation_count": performance_monitor.metrics["validation_count"],
        "success_rate": performance_monitor.get_success_rate(),
        "average_execution_time": performance_monitor.get_average_execution_time(),
        "timestamp": datetime.now().isoformat()
    }
```

---

ã“ã®æŠ€è¡“è©³ç´°èª¬æ˜æ›¸ã«ã‚ˆã‚Šã€ã‚·ã‚¹ãƒ†ãƒ ã®å†…éƒ¨å‹•ä½œã‚’è©³ç´°ã«ç†è§£ã—ã€ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã‚„æ‹¡å¼µã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å½¹å‰²ã¨å®Ÿè£…æ–¹æ³•ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ã§ã€åŠ¹ç‡çš„ãªé–‹ç™ºãƒ»é‹ç”¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

