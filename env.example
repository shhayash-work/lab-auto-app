# LLM Configuration
# Ollama settings (default - local)
OLLAMA_BASE_URL=http://0.0.0.0:6081
OLLAMA_MODEL=llama3.3:latest
EMBEDDING_MODEL=mxbai-embed-large:latest

# Optional: OpenAI API (set to use OpenAI instead of Ollama)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4o

# Optional: Anthropic API (set to use Claude instead of Ollama)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Optional: AWS Bedrock (set to use AWS Bedrock models)
# AWS_ACCESS_KEY_ID=your_aws_access_key_id
# AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key
# AWS_SESSION_TOKEN=your_aws_session_token
# AWS_REGION=us-east-1
# BEDROCK_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# Application settings
APP_NAME="ラボ検証自動化システム"
APP_VERSION="1.0.0"
DEBUG=true

# Database
DATABASE_URL=sqlite:///./lab_validation.db

# Mock Equipment Settings
MOCK_EQUIPMENT_HOST=localhost
MOCK_EQUIPMENT_PORT=8001

# Validation Settings
DEFAULT_VALIDATION_TIMEOUT=300  # seconds
MAX_CONCURRENT_VALIDATIONS=5


